{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "test_notebook.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir6bRzL-hWS3"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8u1YYdC4fZDF"
   },
   "source": [
    "import os"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nk_QX5Fj262O"
   },
   "source": [
    "run_in_colab = True"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zw5izra19Bqg"
   },
   "source": [
    "if run_in_colab:\n",
    "  !pip install transformers\n",
    "  #!pip install wandb\n",
    "  !pip install git+https://github.com/google-research/bleurt.git\n",
    "  !pip install datasets\n",
    "\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  \n",
    "  !git clone https://github.com/nofarmordehai/Learn-Chess-Commentary.git 'chess'\n",
    "  CODE_DIR = 'chess'\n",
    "  os.chdir(f'./{CODE_DIR}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lJIGy7y9cZHa"
   },
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "from Models.GPT2 import GPT2\n",
    "from Models.BERT import BERT\n",
    "from Dataset.MovesDataset import MovesDataset\n",
    "from Configs.train_config import config"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j93CnZ1d9F_Y"
   },
   "source": [
    "if run_in_colab:\n",
    "  BASE_PATH = '/content/drive/MyDrive/NLP/'\n",
    "else:\n",
    "  BASE_PATH = '/home/joberant/nlp_fall_2021/nofarm/chess/'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_VI0s_4NmSbN"
   },
   "source": [
    "games_data_path = BASE_PATH + 'Data/NEW_attack/games_data'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVorMAYKgPKM"
   },
   "source": [
    "# Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9DqzNwQX0ryB"
   },
   "source": [
    "# path_base = BASE_PATH+ u'Models-test/0_1616907487.3351743_0.bin'\n",
    "# path_legal = BASE_PATH+ u'Models-test/0_1616699942.8052278_0-legal.bin'\n",
    "\n",
    "path_attack = BASE_PATH+ u'Models-Final/gpt2.bin'\n",
    "path_bert = BASE_PATH+ u'Models-Final/bert.bin'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6ewKLGmbgWy7"
   },
   "source": [
    "# gpt2 = GPT2() # fen, move, comment\n",
    "# gpt2_legal = GPT2() # fen, move, desc_move, legal_moves, comment\n",
    "\n",
    "gpt2_attack = GPT2() # fen, move, desc_move, attacks and attack by, comment\n",
    "bert = BERT() # fen, move, desc_move, attacks and attack by, comment"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PvwomCrsea-k"
   },
   "source": [
    "# size mismatch for transformer \n",
    "# gpt2_legal.load_model(path_legal)\n",
    "# gpt2.load_model(path_base)\n",
    "\n",
    "gpt2_attack.load_model(path_attack)\n",
    "bert.load_model(path_bert)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WCKvLLXXgeX0"
   },
   "source": [
    "# gpt2.model = gpt2.model.eval()\n",
    "# gpt2_legal.model = gpt2_legal.model.eval()\n",
    "\n",
    "gpt2_attack.model = gpt2_attack.model.eval().cuda()\n",
    "bert.model = bert.model.eval().cuda()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CHDDValinx1F"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Iu0ZCqdyghcL"
   },
   "source": [
    "model = 'gpt2'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3X0Zqq1jgbVc"
   },
   "source": [
    "if model == 'gpt2':\n",
    "  tested_model = gpt2_attack\n",
    "  max = 768\n",
    "  eof = '<|endoftext|>'\n",
    "elif model == 'bert-base':\n",
    "  tested_model = bert\n",
    "  max = 512\n",
    "  eof = 'endoftext'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dAN6XZC2ho6U"
   },
   "source": [
    "pad_token_id = tested_model.tokenizer('[PAD]')['input_ids'][0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7AMjxd-h_jW"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Y_EbPuQSiDOs"
   },
   "source": [
    "# last pickle is our test-set\n",
    "dataset = MovesDataset([f'{games_data_path}{i}.p' for i in [config['NUMER_OF_DATA_DIRS']] ], tested_model.tokenizer, max_length=max)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SNPlpmzLiJ5M"
   },
   "source": [
    "dataloader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3iOYmY503i-"
   },
   "source": [
    "# Humen test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iae-pCrqjqaE"
   },
   "source": [
    "def get_results():\n",
    "  proccessed_data, attn_masks, labels = next(iter(dataloader))\n",
    "\n",
    "  # inputs = []\n",
    "  # targets = []\n",
    "  input_encodings = []\n",
    "  for i in range(config['batch_size']):\n",
    "    textual_data = tested_model.tokenizer.decode(token_ids = proccessed_data[i], skip_special_tokens=False).split('<comment>')\n",
    "\n",
    "    target_text = textual_data[1].split(eof)[0]\n",
    "    # targets.append(target_text)\n",
    "    input_text = textual_data[0] \n",
    "    # inputs.append(input_text)\n",
    "\n",
    "    comment_idx = list(proccessed_data[i]).index(dataset.comment_encoding) + 1\n",
    "    input_encoding = proccessed_data[i][:comment_idx].unsqueeze(0).cuda()\n",
    "    \n",
    "    input_encodings.append(input_encoding)\n",
    "\n",
    "  results = []\n",
    "  for i in range(config['batch_size']):\n",
    "    with torch.no_grad():\n",
    "        outputs = tested_model.model.generate(input_encodings[i], num_beams=2, no_repeat_ngram_size=2, max_length=max+1, pad_token_id=pad_token_id)\n",
    "        output_text = tested_model.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        results.append(output_text)\n",
    "\n",
    "  return results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5VB-5V6ZkLYc"
   },
   "source": [
    "results = get_results()\n",
    "print(results)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVqX0F8ClYG3"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwnIbQcWdL29"
   },
   "source": [
    "every t iterations calculate evaluation metrics for the current model and save the results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EhhbfW1cIcmj"
   },
   "source": [
    "from Evaluation.Metrics import perplexity, bleurt, bleu"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RZq8YhOdZJUX"
   },
   "source": [
    "from Utils import get_targets_and_outputs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qCNmbQA9Djbk"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "W-uo5LT8IcF2"
   },
   "source": [
    "test_perplexity = perplexity(tested_model.model, dataloader)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_51D5Z0dCEfq"
   },
   "source": [
    "print(test_perplexity)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q_EzyTOP0Hko"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8tQK57G1Ib-F"
   },
   "source": [
    "target_texts, output_texts = get_targets_and_outputs(tested_model, dataset, dataset.comment_encoding, pad_token_id, max_length=max, eof=eof)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JpZD-3080MIv"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mUmPJBVEcrl0"
   },
   "source": [
    "test_bleurt = bleurt(target_texts, output_texts)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Tij3zp4rFTX1"
   },
   "source": [
    "print(sum(test_bleurt)/len(test_bleurt))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9lPLBA47CGbd"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zw2vcBxDDjdJ"
   },
   "source": [
    "test_bleu = bleu(target_texts, output_texts)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X0RTcgimFe0r"
   },
   "source": [
    "print(sum(test_bleu)/len(test_bleu))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}